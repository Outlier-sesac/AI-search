import os
import pyodbc
import pandas as pd
import numpy as np
from dotenv import load_dotenv
from openai import AzureOpenAI
from dataclasses import dataclass
from typing import List, Dict, Optional
from datetime import datetime
import json

# --- [ì‹ ê·œ] Azure AI Search ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì¶”ê°€ ---
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from azure.search.documents.indexes import SearchIndexClient
from azure.search.documents.models import VectorizedQuery
from azure.search.documents.indexes.models import (
    SearchIndex,
    SearchField,
    SearchFieldDataType,
    VectorSearch,
    HnswVectorSearchAlgorithmConfiguration,
    VectorSearchProfile,
    SearchableField,
    SimpleField
)


# --- í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì • ---
load_dotenv()

# Azure SQL ì—°ê²° ì •ë³´
server = os.getenv("AZURE_SQL_SERVER")
database = os.getenv("AZURE_SQL_DATABASE")
username = os.getenv("AZURE_SQL_USER")
password = os.getenv("AZURE_SQL_PASSWORD")

# Azure OpenAI ì—°ê²° ì •ë³´
azure_openai_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
azure_openai_key = os.getenv("AZURE_OPENAI_KEY")
azure_openai_version = os.getenv("AZURE_OPENAI_VERSION", "2024-02-01")
embedding_model_name = "text-embedding-3-large"
embedding_dimensions = 3072 # text-embedding-3-large ëª¨ë¸ì˜ ì°¨ì›

# --- [ì‹ ê·œ] Azure AI Search ì—°ê²° ì •ë³´ ---
azure_search_endpoint = os.getenv("AZURE_SEARCH_SERVICE_ENDPOINT")
azure_search_key = os.getenv("AZURE_SEARCH_API_KEY")
azure_search_index_name = os.getenv("AZURE_SEARCH_INDEX_NAME")


# --- ë°ì´í„° í´ë˜ìŠ¤ (ê¸°ì¡´ê³¼ ë™ì¼) ---
@dataclass
class AssemblyMinute:
    """êµ­íšŒ íšŒì˜ë¡ ë°ì´í„° í´ë˜ìŠ¤"""
    minutes_id: str
    minutes_type: str
    minutes_date: datetime
    assembly_number: str
    session_number: str
    sub_session: str
    speech_order: int
    position: Optional[str]
    speaker_name: Optional[str]
    speech_summary: Optional[str]

# --- ì„ë² ë”© ì²˜ë¦¬ í´ë˜ìŠ¤ (ê¸°ì¡´ê³¼ ê±°ì˜ ë™ì¼) ---
class AssemblyMinutesEmbeddingProcessor:
    """êµ­íšŒ íšŒì˜ë¡ ì„ë² ë”© ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.connection_string = f"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}"
        self.openai_client = AzureOpenAI(
            azure_endpoint=azure_openai_endpoint,
            api_key=azure_openai_key,
            api_version=azure_openai_version
        )
        self.embedding_model = embedding_model_name
    
    def connect_to_database(self):
        """Azure SQL Database ì—°ê²°"""
        try:
            conn = pyodbc.connect(self.connection_string)
            print("âœ… Azure SQL Database ì—°ê²° ì„±ê³µ")
            return conn
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def load_assembly_minutes(self, limit: Optional[int] = None) -> List[AssemblyMinute]:
        """dbo.assembly_minutes í…Œì´ë¸”ì—ì„œ ë°ì´í„° ë¡œë“œ"""
        conn = self.connect_to_database()
        if not conn:
            return []
        
        try:
            query = """
            SELECT 
                minutes_id, minutes_type, minutes_date, assembly_number, session_number, 
                sub_session, speech_order, position, speaker_name, speech_summary
            FROM dbo.assembly_minutes
            WHERE speech_summary IS NOT NULL AND LTRIM(RTRIM(speech_summary)) != ''
            ORDER BY minutes_date DESC, speech_order ASC
            """
            
            if limit:
                query += f" OFFSET 0 ROWS FETCH NEXT {limit} ROWS ONLY"
            
            df = pd.read_sql(query, conn)
            print(f"âœ… {len(df)}ê°œì˜ íšŒì˜ë¡ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
            
            assembly_minutes = []
            for _, row in df.iterrows():
                minute = AssemblyMinute(
                    minutes_id=row['minutes_id'], minutes_type=row['minutes_type'],
                    minutes_date=pd.to_datetime(row['minutes_date']), assembly_number=row['assembly_number'],
                    session_number=row['session_number'], sub_session=row['sub_session'],
                    speech_order=int(row['speech_order']) if pd.notna(row['speech_order']) else 0,
                    position=row['position'] if pd.notna(row['position']) else None,
                    speaker_name=row['speaker_name'] if pd.notna(row['speaker_name']) else None,
                    speech_summary=row['speech_summary'] if pd.notna(row['speech_summary']) else None
                )
                assembly_minutes.append(minute)
            
            return assembly_minutes
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
        finally:
            conn.close()
    
    def create_contextual_text(self, minute: AssemblyMinute) -> str:
        # ... (ê¸°ì¡´ê³¼ ë™ì¼)
        context_parts = [
            f"{minute.assembly_number} {minute.session_number} {minute.sub_session}",
            f"{minute.minutes_date.strftime('%Yë…„ %mì›” %dì¼')}",
            f"íšŒì˜ìœ í˜•: {minute.minutes_type}"
        ]
        if minute.speaker_name:
            speaker_context = f"ë°œì–¸ì: {minute.speaker_name}"
            if minute.position: speaker_context += f" ({minute.position})"
            context_parts.append(speaker_context)
        if minute.speech_order: context_parts.append(f"ë°œì–¸ìˆœì„œ: {minute.speech_order}")
        context_text = " | ".join(context_parts)
        full_text = f"{context_text}\n\në°œì–¸ë‚´ìš©: {minute.speech_summary}"
        return full_text
    
    def create_embeddings_batch(self, minutes: List[AssemblyMinute], batch_size: int = 50) -> List[Dict]:
        """ë°°ì¹˜ë¡œ ì„ë² ë”© ìƒì„± ë° ë©”íƒ€ë°ì´í„°ì™€ í•¨ê»˜ ë°˜í™˜ (AI Search ì—…ë¡œë“œ í˜•ì‹ì— ë§ê²Œ ìˆ˜ì •)"""
        results = []
        for i in range(0, len(minutes), batch_size):
            batch = minutes[i:i + batch_size]
            batch_texts = [self.create_contextual_text(minute) for minute in batch]
            
            try:
                response = self.openai_client.embeddings.create(input=batch_texts, model=self.embedding_model)
                for j, minute in enumerate(batch):
                    document = {
                        "document_id": f"{minute.minutes_id}_{minute.speech_order}",
                        "minutes_id": minute.minutes_id,
                        "minutes_type": minute.minutes_type,
                        "minutes_date": minute.minutes_date,
                        "assembly_number": minute.assembly_number,
                        "session_number": minute.session_number,
                        "sub_session": minute.sub_session,
                        "speech_order": minute.speech_order,
                        "position": minute.position,
                        "speaker_name": minute.speaker_name,
                        "content": self.create_contextual_text(minute), # ê²€ìƒ‰ ê²°ê³¼ í™•ì¸ìš© ì›ë³¸ í…ìŠ¤íŠ¸
                        "embedding": response.data[j].embedding
                    }
                    results.append(document)
                print(f"âœ… ë°°ì¹˜ {i//batch_size + 1}/{(len(minutes)-1)//batch_size + 1} ì™„ë£Œ: {len(batch)}ê°œ ì„ë² ë”© ìƒì„±")
            except Exception as e:
                print(f"âŒ ë°°ì¹˜ {i//batch_size + 1} ì‹¤íŒ¨: {e}")
                continue
        return results

# --- [ì‹ ê·œ] Azure AI Search ì¸ë±ì„œ í´ë˜ìŠ¤ ---
class AzureAISearchIndexer:
    """Azure AI Search ì¸ë±ìŠ¤ë¥¼ ê´€ë¦¬í•˜ê³  ë¬¸ì„œë¥¼ ì—…ë¡œë“œí•˜ëŠ” í´ë˜ìŠ¤"""

    def __init__(self, endpoint: str, key: str, index_name: str):
        self.endpoint = endpoint
        self.key = key
        self.index_name = index_name
        self.credential = AzureKeyCredential(key)
        self.index_client = SearchIndexClient(endpoint, self.credential)
        self.search_client = SearchClient(endpoint, index_name, self.credential)

    def create_or_update_index(self):
        """AI Search ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ê±°ë‚˜ ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤."""
        fields = [
            SimpleField(name="document_id", type=SearchFieldDataType.String, key=True),
            SimpleField(name="minutes_id", type=SearchFieldDataType.String, filterable=True, sortable=True, facetable=True),
            SearchableField(name="content", type=SearchFieldDataType.String, searchable=True),
            SearchField(name="embedding", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),
                        searchable=True, vector_search_dimensions=embedding_dimensions, vector_search_profile_name="my-hnsw-profile"),
            SimpleField(name="minutes_type", type=SearchFieldDataType.String, filterable=True, facetable=True),
            SimpleField(name="minutes_date", type=SearchFieldDataType.DateTimeOffset, filterable=True, sortable=True),
            SimpleField(name="assembly_number", type=SearchFieldDataType.String, filterable=True, facetable=True),
            SimpleField(name="session_number", type=SearchFieldDataType.String, filterable=True, facetable=True),
            SimpleField(name="sub_session", type=SearchFieldDataType.String, filterable=True, facetable=True),
            SimpleField(name="speech_order", type=SearchFieldDataType.Int32, filterable=True, sortable=True),
            SimpleField(name="position", type=SearchFieldDataType.String, filterable=True, facetable=True),
            SimpleField(name="speaker_name", type=SearchFieldDataType.String, filterable=True, facetable=True, searchable=True)
        ]

        vector_search = VectorSearch(
            profiles=[VectorSearchProfile(name="my-hnsw-profile", algorithm_configuration_name="my-hnsw-config")],
            algorithms=[HnswVectorSearchAlgorithmConfiguration(name="my-hnsw-config", kind="hnsw", parameters={"metric": "cosine"})]
        )

        index = SearchIndex(name=self.index_name, fields=fields, vector_search=vector_search)
        
        try:
            print(f"ğŸ”„ '{self.index_name}' ì¸ë±ìŠ¤ë¥¼ ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤...")
            self.index_client.create_or_update_index(index)
            print("âœ… ì¸ë±ìŠ¤ ì¤€ë¹„ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì¸ë±ìŠ¤ ìƒì„±/ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            raise

    def upload_documents(self, documents: List[Dict], batch_size: int = 1000):
        """ë¬¸ì„œë¥¼ AI Searchì— ë°°ì¹˜ë¡œ ì—…ë¡œë“œí•©ë‹ˆë‹¤."""
        for i in range(0, len(documents), batch_size):
            batch = documents[i:i + batch_size]
            try:
                result = self.search_client.upload_documents(documents=batch)
                print(f"âœ… ë¬¸ì„œ {i+1}-{i+len(batch)} ì—…ë¡œë“œ ì„±ê³µ. ì„±ê³µ ê°œìˆ˜: {sum(1 for r in result if r.succeeded)}")
            except Exception as e:
                print(f"âŒ ë¬¸ì„œ ë°°ì¹˜ ì—…ë¡œë“œ ì‹¤íŒ¨: {e}")

# --- [ì‹ ê·œ] Azure AI Search ê²€ìƒ‰ í•¨ìˆ˜ ---
def perform_vector_search(query_text: str, k: int = 5):
    """ì£¼ì–´ì§„ ì¿¼ë¦¬ í…ìŠ¤íŠ¸ë¡œ Azure AI Searchì—ì„œ ë²¡í„° ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
    
    print("\n\n--- ğŸš€ Azure AI Search ë²¡í„° ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹œì‘ ---")
    
    # 1. í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
    openai_client = AzureOpenAI(
        azure_endpoint=azure_openai_endpoint,
        api_key=azure_openai_key,
        api_version=azure_openai_version
    )
    search_client = SearchClient(azure_search_endpoint, azure_search_index_name, AzureKeyCredential(azure_search_key))

    # 2. ì¿¼ë¦¬ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„±
    print(f"ğŸ” ê²€ìƒ‰ ì¿¼ë¦¬: '{query_text}'")
    query_embedding = openai_client.embeddings.create(input=[query_text], model=embedding_model_name).data[0].embedding
    
    # 3. ë²¡í„° ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„±
    vector_query = VectorizedQuery(
        vector=query_embedding,
        k_nearest_neighbors=k,
        fields="embedding" # ê²€ìƒ‰í•  ë²¡í„° í•„ë“œ ì´ë¦„
    )
    
    # 4. ê²€ìƒ‰ ìˆ˜í–‰
    results = search_client.search(
        search_text=None, # í‚¤ì›Œë“œ ê²€ìƒ‰ì€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        vector_queries=[vector_query],
        select=["document_id", "speaker_name", "position", "minutes_date", "content"] # ë°˜í™˜ë°›ì„ í•„ë“œ ëª©ë¡
    )

    # 5. ê²°ê³¼ ì¶œë ¥
    print(f"\nâœ¨ Top {k} ê²€ìƒ‰ ê²°ê³¼:")
    for result in results:
        print("-" * 50)
        print(f"  [ê²°ê³¼] ìœ ì‚¬ë„ ì ìˆ˜: {result['@search.score']:.4f}")
        print(f"  ë°œì–¸ì: {result.get('speaker_name', 'N/A')} ({result.get('position', 'N/A')})")
        print(f"  íšŒì˜ì¼: {result.get('minutes_date').strftime('%Y-%m-%d') if result.get('minutes_date') else 'N/A'}")
        print(f"  ë‚´ìš© ì¼ë¶€: {result.get('content', '').replace(chr(10), ' ').replace(chr(13), ' ')[:200]}...")
        print("-" * 50)


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # --- 1. ì„ë² ë”© ìƒì„± ---
    processor = AssemblyMinutesEmbeddingProcessor()
    print("ğŸ”„ êµ­íšŒ íšŒì˜ë¡ ë°ì´í„° ë¡œë“œ ì¤‘...")
    assembly_minutes = processor.load_assembly_minutes(limit=1000) # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ 1000ê°œ ë¡œë“œ
    
    if not assembly_minutes:
        print("âŒ ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print("ğŸ”„ ì„ë² ë”© ë²¡í„° ìƒì„± ë° ë¬¸ì„œ í˜•ì‹ ì¤€ë¹„ ì¤‘...")
    documents_to_upload = processor.create_embeddings_batch(assembly_minutes, batch_size=50)

    # --- 2. Azure AI Search ì¸ë±ìŠ¤ ìƒì„± ë° ë°ì´í„° ì—…ë¡œë“œ ---
    if documents_to_upload:
        indexer = AzureAISearchIndexer(
            endpoint=azure_search_endpoint,
            key=azure_search_key,
            index_name=azure_search_index_name
        )
        # 2.1. ì¸ë±ìŠ¤ ìƒì„± (ì—†ìœ¼ë©´ ë§Œë“¤ê³ , ìˆìœ¼ë©´ í•„ë“œ ì •ì˜ì— ë”°ë¼ ì—…ë°ì´íŠ¸)
        indexer.create_or_update_index()

        # 2.2. ë¬¸ì„œ ì—…ë¡œë“œ
        print("\nğŸ”„ ìƒì„±ëœ ë¬¸ì„œë¥¼ Azure AI Searchì— ì—…ë¡œë“œí•©ë‹ˆë‹¤...")
        indexer.upload_documents(documents_to_upload)
    else:
        print("âŒ ìƒì„±ëœ ì„ë² ë”©ì´ ì—†ì–´ ì—…ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # --- 3. (ë³´ë„ˆìŠ¤) ì—…ë¡œë“œëœ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•œ ë²¡í„° ê²€ìƒ‰ ì˜ˆì‹œ ---
    perform_vector_search(query_text="ì €ì¶œìƒ ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ì •ë¶€ì˜ ì—­í• ")


if __name__ == "__main__":
    main()