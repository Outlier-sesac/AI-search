import os
import pyodbc
import pandas as pd
from dotenv import load_dotenv
from openai import AzureOpenAI
from dataclasses import dataclass, field
from typing import List, Dict, Optional, Any
from datetime import datetime, timezone

# --- Azure AI Search ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ (v11.5.x ì•ˆì • ë²„ì „ì— ë§ê²Œ ìˆ˜ì •) ---
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from azure.search.documents.indexes import SearchIndexClient
from azure.search.documents.models import VectorizedQuery
from azure.search.documents.indexes.models import (
    SearchIndex,
    SearchField,
    SearchFieldDataType,
    VectorSearch,
    HnswAlgorithmConfiguration,
    VectorSearchProfile,
    HnswParameters,
    SearchableField,
    SimpleField
)

# --- í™˜ê²½ ë³€ìˆ˜ ë° ì„¤ì • ---
load_dotenv()

# Azure SQL ì—°ê²° ì •ë³´
server = os.getenv("AZURE_SQL_SERVER")
database = os.getenv("AZURE_SQL_DATABASE")
username = os.getenv("AZURE_SQL_USER")
password = os.getenv("AZURE_SQL_PASSWORD")

# Azure OpenAI ì—°ê²° ì •ë³´
azure_openai_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
azure_openai_key = os.getenv("AZURE_OPENAI_KEY")
azure_openai_version = os.getenv("AZURE_OPENAI_VERSION", "2024-02-01")
embedding_model_name = "text-embedding-3-large"
embedding_dimensions = 3072

# Azure AI Search ì—°ê²° ì •ë³´
azure_search_endpoint = os.getenv("AZURE_SEARCH_ENDPOINT")
azure_search_key = os.getenv("AZURE_SEARCH_ADMIN_KEY")
azure_search_index_name = os.getenv("AZURE_SEARCH_INDEX_NAME")

# --- ë°ì´í„° í´ë˜ìŠ¤ ---
# DB ìŠ¤í‚¤ë§ˆì™€ ì •í™•íˆ ì¼ì¹˜í•˜ë„ë¡, speech_summary_vector í•„ë“œ ì¶”ê°€
@dataclass
class AssemblyMinute:
    minutes_id: str
    minutes_type: str
    minutes_date: datetime
    assembly_number: str
    session_number: str
    sub_session: str
    speech_order: int
    position: Optional[str]
    speaker_name: Optional[str]
    speech_summary: Optional[str]
    # DBì— í•´ë‹¹ ì»¬ëŸ¼ì´ ìˆë‹¤ë©´ ì¶”ê°€. ì—†ë‹¤ë©´ ì´ ì¤„ì„ ì‚­ì œí•˜ì„¸ìš”.
    speech_summary_vector: Optional[Any] = field(default=None)

# --- ì„ë² ë”© ì²˜ë¦¬ í´ë˜ìŠ¤ ---
class AssemblyMinutesEmbeddingProcessor:
    def __init__(self):
        self.connection_string = f"DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}"
        self.openai_client = AzureOpenAI(
            azure_endpoint=azure_openai_endpoint,
            api_key=azure_openai_key,
            api_version=azure_openai_version
        )
        self.embedding_model = embedding_model_name
    
    def connect_to_database(self):
        try:
            conn = pyodbc.connect(self.connection_string)
            print("âœ… Azure SQL Database ì—°ê²° ì„±ê³µ")
            return conn
        except Exception as e:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def load_assembly_minutes(self, limit: Optional[int] = None) -> List[AssemblyMinute]:
        conn = self.connect_to_database()
        if not conn: return []
        
        try:
            query = "SELECT * FROM dbo.assembly_minutes WHERE speech_summary IS NOT NULL AND LTRIM(RTRIM(speech_summary)) <> '' ORDER BY minutes_date DESC, speech_order ASC"
            if limit:
                query += f" OFFSET 0 ROWS FETCH NEXT {limit} ROWS ONLY"
            
            df = pd.read_sql(query, conn)
            print(f"âœ… {len(df)}ê°œì˜ íšŒì˜ë¡ ë°ì´í„° ë¡œë“œ ì™„ë£Œ")

            assembly_minutes = []
            for _, row in df.iterrows():
                dt = pd.to_datetime(row['minutes_date'])
                dt = dt.replace(tzinfo=timezone.utc) if dt.tzinfo is None else dt.astimezone(timezone.utc)
                row_data = row.to_dict()
                row_data['minutes_date'] = dt
                row_data['speech_order'] = int(row_data['speech_order']) if pd.notna(row_data['speech_order']) else 0
                
                # ë°ì´í„°í´ë˜ìŠ¤ì— ì—†ëŠ” í•„ë“œëŠ” ì œì™¸í•˜ê³  ê°ì²´ ìƒì„±
                valid_keys = {f.name for f in AssemblyMinute.__dataclass_fields__.values()}
                filtered_data = {k: v for k, v in row_data.items() if k in valid_keys}

                assembly_minutes.append(AssemblyMinute(**filtered_data))
            
            return assembly_minutes
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
            return []
        finally:
            if conn: conn.close()
    
    def create_contextual_text(self, minute: AssemblyMinute) -> str:
        context_parts = [
            f"{minute.assembly_number} {minute.session_number} {minute.sub_session}",
            f"{minute.minutes_date.strftime('%Yë…„ %mì›” %dì¼')}",
            f"íšŒì˜ìœ í˜•: {minute.minutes_type}"
        ]
        if minute.speaker_name:
            context_parts.append(f"ë°œì–¸ì: {minute.speaker_name} ({minute.position or ''})".strip())
        if minute.speech_order: 
            context_parts.append(f"ë°œì–¸ìˆœì„œ: {minute.speech_order}")
        return f"{' | '.join(context_parts)}\n\në°œì–¸ë‚´ìš©: {minute.speech_summary}"
    
    def create_embeddings_batch(self, minutes: List[AssemblyMinute], batch_size: int = 50) -> List[Dict]:
        results = []
        for i in range(0, len(minutes), batch_size):
            batch = minutes[i:i + batch_size]
            batch_texts = [self.create_contextual_text(minute) for minute in batch]
            try:
                response = self.openai_client.embeddings.create(input=batch_texts, model=self.embedding_model)
                for j, minute in enumerate(batch):
                    doc = {
                        "document_id": f"{minute.minutes_id}_{minute.speech_order}",
                        "minutes_id": minute.minutes_id,
                        "minutes_type": minute.minutes_type,
                        "minutes_date": minute.minutes_date.isoformat(),
                        "assembly_number": minute.assembly_number,
                        "session_number": minute.session_number,
                        "sub_session": minute.sub_session,
                        "speech_order": minute.speech_order,
                        "position": minute.position,
                        "speaker_name": minute.speaker_name,
                        "content": batch_texts[j],
                        "embedding": response.data[j].embedding
                    }
                    results.append(doc)
                print(f"âœ… ë°°ì¹˜ {i//batch_size + 1}/{(len(minutes)-1)//batch_size + 1} ì™„ë£Œ: {len(batch)}ê°œ ì„ë² ë”© ìƒì„±")
            except Exception as e:
                print(f"âŒ ë°°ì¹˜ {i//batch_size + 1} ì‹¤íŒ¨: {e}")
                continue
        return results

# --- Azure AI Search ì¸ë±ì„œ í´ë˜ìŠ¤ (v11.5.3 ìµœì¢…ë³¸) ---
class AzureAISearchIndexer:
    def __init__(self, endpoint: str, key: str, index_name: str):
        self.credential = AzureKeyCredential(key)
        self.index_client = SearchIndexClient(endpoint, self.credential)
        self.search_client = SearchClient(endpoint, index_name, self.credential)
        self.index_name = index_name

    def create_or_update_index(self):
        fields = [
            SimpleField(name="document_id", type=SearchFieldDataType.String, key=True),
            SimpleField(name="minutes_id", type=SearchFieldDataType.String, filterable=True, facetable=True),
            SearchableField(name="content", type=SearchFieldDataType.String, searchable=True),
            SearchField(name="embedding", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),
                        searchable=True, vector_search_dimensions=embedding_dimensions,
                        vector_search_profile_name="my-hnsw-profile"),
            SimpleField(name="minutes_type", type=SearchFieldDataType.String, filterable=True, facetable=True),
            SimpleField(name="minutes_date", type=SearchFieldDataType.DateTimeOffset, filterable=True, sortable=True),
            SimpleField(name="assembly_number", type=SearchFieldDataType.String, filterable=True, facetable=True),
            SimpleField(name="session_number", type=SearchFieldDataType.String, filterable=True, facetable=True),
            SimpleField(name="sub_session", type=SearchFieldDataType.String, filterable=True, facetable=True),
            SimpleField(name="speech_order", type=SearchFieldDataType.Int32, filterable=True, sortable=True),
            SimpleField(name="position", type=SearchFieldDataType.String, filterable=True, facetable=True),
            SimpleField(name="speaker_name", type=SearchFieldDataType.String, filterable=True, facetable=True)
        ]

        vector_search = VectorSearch(
            algorithms=[
                HnswAlgorithmConfiguration(
                    name="my-hnsw-algo",
                    kind="hnsw",
                    parameters=HnswParameters(metric="cosine")
                )
            ],
            profiles=[
                VectorSearchProfile(
                    name="my-hnsw-profile",
                    algorithm_configuration_name="my-hnsw-algo"
                )
            ]
        )

        index = SearchIndex(name=self.index_name, fields=fields, vector_search=vector_search)
        
        try:
            print(f"ğŸ”„ '{self.index_name}' ì¸ë±ìŠ¤ë¥¼ ìƒì„± ë˜ëŠ” ì—…ë°ì´íŠ¸í•©ë‹ˆë‹¤...")
            self.index_client.create_or_update_index(index)
            print("âœ… ì¸ë±ìŠ¤ ì¤€ë¹„ ì™„ë£Œ")
        except Exception as e:
            print(f"âŒ ì¸ë±ìŠ¤ ìƒì„±/ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
            raise

    # [í•µì‹¬ ìˆ˜ì •] ë¬¸ì„œë¥¼ ì‘ì€ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ ì—…ë¡œë“œí•˜ëŠ” í•¨ìˆ˜
    def upload_documents(self, documents: List[Dict], batch_size: int = 500):
        """ë¬¸ì„œë¥¼ ì‘ì€ ë°°ì¹˜ë¡œ ë‚˜ëˆ„ì–´ AI Searchì— ì—…ë¡œë“œí•©ë‹ˆë‹¤."""
        for i in range(0, len(documents), batch_size):
            batch = documents[i:i + batch_size]
            try:
                result = self.search_client.upload_documents(documents=batch)
                success_count = sum(1 for r in result if r.succeeded)
                print(f"âœ… ë°°ì¹˜ {i//batch_size + 1} ì—…ë¡œë“œ ì™„ë£Œ: {success_count}/{len(batch)} ì„±ê³µ")
                if success_count < len(batch):
                    for r in result:
                        if not r.succeeded:
                            print(f"  âŒ ì‹¤íŒ¨: document_id={r.key}, message={r.error_message}")
            except Exception as e:
                print(f"âŒ ë°°ì¹˜ {i//batch_size + 1} ì—…ë¡œë“œ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")

# --- ë©”ì¸ ì‹¤í–‰ ë¡œì§ ---
def main():
    processor = AssemblyMinutesEmbeddingProcessor()
    minutes = processor.load_assembly_minutes(limit=None)
    if not minutes: 
        print("âŒ ë¡œë“œí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    documents = processor.create_embeddings_batch(minutes)
    if not documents: 
        print("âŒ ìƒì„±ëœ ì„ë² ë”©ì´ ì—†ì–´ ì—…ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    indexer = AzureAISearchIndexer(azure_search_endpoint, azure_search_key, azure_search_index_name)
    indexer.create_or_update_index()
    
    # ìˆ˜ì •ëœ upload_documents í•¨ìˆ˜ í˜¸ì¶œ
    indexer.upload_documents(documents)

if __name__ == "__main__":
    main()