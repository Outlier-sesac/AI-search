import os
from typing import List, Dict, Optional, Literal, Annotated
from datetime import datetime
from dotenv import load_dotenv
from openai import AzureOpenAI
from azure.core.credentials import AzureKeyCredential
from azure.search.documents import SearchClient
from azure.search.documents.models import VectorizedQuery
from tavily import TavilyClient
import concurrent.futures
import time
from functools import lru_cache
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langchain_core.tools import tool
from langgraph.graph import StateGraph, MessagesState, START, END
from langgraph.types import Command
from typing_extensions import TypedDict

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ì„¤ì • ì •ë³´
azure_openai_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
azure_openai_key = os.getenv("AZURE_OPENAI_KEY")
azure_openai_version = os.getenv("AZURE_OPENAI_VERSION", "2024-02-01")
embedding_model_name = "text-embedding-3-large"
chat_model_name = "gpt-35-turbo"

azure_search_endpoint = os.getenv("AZURE_SEARCH_ENDPOINT")
azure_search_key = os.getenv("AZURE_SEARCH_ADMIN_KEY")
azure_search_index_name = os.getenv("AZURE_SEARCH_INDEX_NAME")
tavily_api_key = os.getenv("TAVILY_API_KEY")

class AgentState(TypedDict):
    """ì—ì´ì „íŠ¸ ìƒíƒœ ì •ì˜"""
    messages: Annotated[List[BaseMessage], lambda x, y: x + y]
    query: str
    search_strategy: str
    internal_results: List[Dict]
    external_results: List[Dict]
    final_answer: str
    processing_info: Dict
    step_count: int  # ë‹¨ê³„ ì¶”ì ì„ ìœ„í•œ ì¹´ìš´í„° ì¶”ê°€

class SearchAgents:
    """ê²€ìƒ‰ ì—ì´ì „íŠ¸ë“¤ì„ ê´€ë¦¬í•˜ëŠ” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.openai_client = AzureOpenAI(
            azure_endpoint=azure_openai_endpoint,
            api_key=azure_openai_key,
            api_version=azure_openai_version
        )
        
        self.search_client = SearchClient(
            azure_search_endpoint, 
            azure_search_index_name, 
            AzureKeyCredential(azure_search_key)
        )
        
        self.tavily_client = TavilyClient(api_key=tavily_api_key) if tavily_api_key else None
        
        self.embedding_model = embedding_model_name
        self.chat_model = chat_model_name
        self.embedding_cache = {}
        self.max_cache_size = 1000
    
    @lru_cache(maxsize=100)
    def _safe_date_format(self, date_value, format_type='korean'):
        """ë‚ ì§œ ê°’ì„ ìŒì„±ìœ¼ë¡œ ë“£ê¸° ì‰½ê²Œ í¬ë§·íŒ…"""
        if not date_value:
            return "ë‚ ì§œ ì •ë³´ ì—†ìŒ"
        
        try:
            if hasattr(date_value, 'strftime'):
                return date_value.strftime('%Yë…„ %mì›” %dì¼')
            elif isinstance(date_value, str):
                date_formats = [
                    '%Y-%m-%d', '%Y-%m-%d %H:%M:%S', '%Y-%m-%dT%H:%M:%S',
                    '%Y-%m-%dT%H:%M:%S.%f', '%Y-%m-%dT%H:%M:%S.%fZ',
                    '%Y/%m/%d', '%m/%d/%Y', '%Y.%m.%d'
                ]
                
                for fmt in date_formats:
                    try:
                        parsed_date = datetime.strptime(date_value, fmt)
                        return parsed_date.strftime('%Yë…„ %mì›” %dì¼')
                    except ValueError:
                        continue
                return str(date_value)
            else:
                return str(date_value)
        except Exception:
            return str(date_value) if date_value else "ë‚ ì§œ ì •ë³´ ì—†ìŒ"
    
    def _get_cached_embedding(self, text: str) -> List[float]:
        """ì„ë² ë”© ìºì‹±ìœ¼ë¡œ ì†ë„ ê°œì„ """
        if text in self.embedding_cache:
            return self.embedding_cache[text]
        
        if len(self.embedding_cache) >= self.max_cache_size:
            oldest_key = next(iter(self.embedding_cache))
            del self.embedding_cache[oldest_key]
        
        embedding = self.openai_client.embeddings.create(
            input=[text], 
            model=self.embedding_model
        ).data[0].embedding
        
        self.embedding_cache[text] = embedding
        return embedding
    
    def _preprocess_query_for_context(self, query: str) -> str:
        """ìŒì„± ì…ë ¥ì„ ê³ ë ¤í•œ ì¿¼ë¦¬ ì „ì²˜ë¦¬ ë° ë§¥ë½ í™•ì¥"""
        query_corrections = {
            'ì €ì¶œì‚°': 'ì €ì¶œìƒ',
            'ì €ì¶œìƒ': 'ì €ì¶œìƒ ì €ì¶œì‚° ì¶œìƒë¥ ',
            'ê¸°í›„ë³€í™”': 'ê¸°í›„ë³€í™” í™˜ê²½ íƒ„ì†Œì¤‘ë¦½',
            'ë¶€ë™ì‚°': 'ë¶€ë™ì‚° ì£¼íƒ ì„ëŒ€ë£Œ',
            'êµìœ¡': 'êµìœ¡ í•™êµ ëŒ€í•™ í•™ìƒ',
            'ì˜ë£Œ': 'ì˜ë£Œ ë³‘ì› ê±´ê°•ë³´í—˜',
            'ë³µì§€': 'ë³µì§€ ì‚¬íšŒë³´ì¥ ì—°ê¸ˆ',
            'ê²½ì œ': 'ê²½ì œ ì¼ìë¦¬ ê³ ìš©',
            'êµ­ì •ê°ì‚¬': 'êµ­ì •ê°ì‚¬ êµ­ê°',
            'ì˜ˆì‚°': 'ì˜ˆì‚° ì¬ì • ì„¸ê¸ˆ',
            'í™˜ê²½': 'í™˜ê²½ ê¸°í›„ë³€í™” íƒ„ì†Œì¤‘ë¦½ ì¹œí™˜ê²½',
            'ë°œì˜ì•ˆ': 'ë°œì˜ì•ˆ ë²•ì•ˆ ì˜ì•ˆ'
        }
        
        expanded_query = query
        for key, expansion in query_corrections.items():
            if key in query:
                expanded_query = f"{query} {expansion}"
                break
        
        return expanded_query

# ê²€ìƒ‰ ì—ì´ì „íŠ¸ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
search_agents = SearchAgents()

# ë„êµ¬ ì •ì˜
@tool
def internal_search_tool(query: str, k: int = 5) -> List[Dict]:
    """êµ­íšŒ íšŒì˜ë¡ ë‚´ë¶€ ê²€ìƒ‰ ë„êµ¬"""
    try:
        processed_query = search_agents._preprocess_query_for_context(query)
        query_embedding = search_agents._get_cached_embedding(processed_query)
        
        vector_query = VectorizedQuery(
            vector=query_embedding,
            k_nearest_neighbors=k,
            fields="embedding"
        )
        
        results = search_agents.search_client.search(
            search_text=None,
            vector_queries=[vector_query],
            select=[
                "document_id", "speaker_name", "position", 
                "minutes_date", "content", "assembly_number", 
                "session_number", "minutes_type"
            ]
        )
        
        documents = []
        for result in results:
            doc = {
                "document_id": result.get("document_id"),
                "speaker_name": result.get("speaker_name"),
                "position": result.get("position"),
                "minutes_date": result.get("minutes_date"),
                "content": result.get("content"),
                "assembly_number": result.get("assembly_number"),
                "session_number": result.get("session_number"),
                "minutes_type": result.get("minutes_type"),
                "score": result.get("@search.score", 0),
                "source_type": "internal",
                "source_name": "êµ­íšŒ íšŒì˜ë¡"
            }
            documents.append(doc)
        
        return documents
        
    except Exception as e:
        print(f"ë‚´ë¶€ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return []

@tool
def external_search_tool(query: str, k: int = 5) -> List[Dict]:
    """Tavily API ì™¸ë¶€ ê²€ìƒ‰ ë„êµ¬"""
    if not search_agents.tavily_client:
        return []
    
    try:
        response = search_agents.tavily_client.search(
            query=query,
            max_results=k,
            search_depth="advanced",
            include_answer=True,
            include_images=False
        )
        
        documents = []
        
        if response.get('answer'):
            doc = {
                "content": response['answer'],
                "title": f"{query}ì— ëŒ€í•œ ìš”ì•½ ë‹µë³€",
                "url": "tavily_summary",
                "score": 1.0,
                "source_type": "external_summary",
                "source_name": "Tavily ìš”ì•½"
            }
            documents.append(doc)
        
        for result in response.get('results', []):
            doc = {
                "content": result.get('content', ''),
                "title": result.get('title', ''),
                "url": result.get('url', ''),
                "score": result.get('score', 0),
                "source_type": "external",
                "source_name": "ì›¹ ê²€ìƒ‰"
            }
            documents.append(doc)
        
        return documents
        
    except Exception as e:
        print(f"ì™¸ë¶€ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return []

@tool
def strategy_analyzer_tool(query: str) -> str:
    """ì¿¼ë¦¬ ë¶„ì„í•˜ì—¬ ê²€ìƒ‰ ì „ëµ ê²°ì • ë„êµ¬"""
    assembly_keywords = [
        'êµ­íšŒ', 'ì˜ì›', 'êµ­ì •ê°ì‚¬', 'êµ­ê°', 'íšŒì˜ë¡', 'ë³¸íšŒì˜', 'ìœ„ì›íšŒ',
        'ë²•ì•ˆ', 'ì˜ˆì‚°', 'ì •ë¶€', 'ì¥ê´€', 'ëŒ€í†µë ¹', 'ì˜ì¥', 'êµ­íšŒì˜ì›', 'ë°œì˜ì•ˆ'
    ]
    
    current_keywords = [
        'ìµœê·¼', 'í˜„ì¬', 'ì§€ê¸ˆ', 'ì˜¤ëŠ˜', 'ì´ë²ˆ', 'ì˜¬í•´', '2024', '2025',
        'ìµœì‹ ', 'ë™í–¥', 'íŠ¸ë Œë“œ', 'ë‰´ìŠ¤', 'ì†Œì‹'
    ]
    
    general_keywords = [
        'ì„¤ëª…', 'ì •ì˜', 'ì˜ë¯¸', 'ê°œë…', 'ì—­ì‚¬', 'ë°°ê²½', 'ì›ì¸', 'ì´ìœ '
    ]
    
    query_lower = query.lower()
    
    assembly_score = sum(1 for keyword in assembly_keywords if keyword in query_lower)
    current_score = sum(1 for keyword in current_keywords if keyword in query_lower)
    general_score = sum(1 for keyword in general_keywords if keyword in query_lower)
    
    if assembly_score >= 2:
        return "internal_only"
    elif current_score >= 1:
        return "external_priority"
    elif general_score >= 1:
        return "hybrid_balanced"
    else:
        return "hybrid_internal_priority"

# ì—ì´ì „íŠ¸ ë…¸ë“œ í•¨ìˆ˜ë“¤ - ë¬´í•œ ë£¨í”„ ë°©ì§€ ê°œì„ 
def entry_node(state: AgentState) -> AgentState:
    """ì§„ì…ì  ë…¸ë“œ - ì¿¼ë¦¬ ì¶”ì¶œ ë° ì´ˆê¸°í™”"""
    messages = state.get("messages", [])
    
    if not messages:
        return {
            **state,
            "final_answer": "ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤.",
            "step_count": state.get("step_count", 0) + 1
        }
    
    # ë§ˆì§€ë§‰ ë©”ì‹œì§€ì—ì„œ ì¿¼ë¦¬ ì¶”ì¶œ
    last_message = messages[-1]
    if isinstance(last_message, HumanMessage):
        query = last_message.content
        
        print(f"ğŸ¯ ì§„ì…ì : ì§ˆë¬¸ '{query}' ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤")
        
        return {
            **state,
            "query": query,
            "processing_info": {"start_time": time.time()},
            "step_count": state.get("step_count", 0) + 1
        }
    
    return {
        **state,
        "final_answer": "ìœ íš¨í•œ ì§ˆë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
        "step_count": state.get("step_count", 0) + 1
    }

def strategy_node(state: AgentState) -> AgentState:
    """ì „ëµ ê²°ì • ë…¸ë“œ"""
    query = state.get("query", "")
    
    if not query:
        return {
            **state,
            "final_answer": "ì§ˆë¬¸ì´ ì—†ì–´ ì „ëµì„ ê²°ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
            "step_count": state.get("step_count", 0) + 1
        }
    
    # ì „ëµ ë¶„ì„ ë„êµ¬ ì‚¬ìš©
    strategy = strategy_analyzer_tool.invoke({"query": query})
    
    strategy_names = {
        "internal_only": "êµ­íšŒ íšŒì˜ë¡ ì „ìš©",
        "external_priority": "ìµœì‹  ì •ë³´ ìš°ì„ ",
        "hybrid_balanced": "ê· í˜• ê²€ìƒ‰",
        "hybrid_internal_priority": "êµ­íšŒ ìš°ì„ "
    }
    
    print(f"ğŸ¤– ì „ëµ ë…¸ë“œ: '{strategy_names.get(strategy, strategy)}' ì „ëµì„ ì„ íƒí–ˆìŠµë‹ˆë‹¤")
    
    return {
        **state,
        "search_strategy": strategy,
        "step_count": state.get("step_count", 0) + 1
    }

def search_node(state: AgentState) -> AgentState:
    """í†µí•© ê²€ìƒ‰ ë…¸ë“œ - ì „ëµì— ë”°ë¼ ê²€ìƒ‰ ìˆ˜í–‰"""
    query = state.get("query", "")
    strategy = state.get("search_strategy", "")
    
    if not query or not strategy:
        return {
            **state,
            "final_answer": "ê²€ìƒ‰ì— í•„ìš”í•œ ì •ë³´ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.",
            "step_count": state.get("step_count", 0) + 1
        }
    
    print(f"ğŸ” ê²€ìƒ‰ ë…¸ë“œ: {strategy} ì „ëµìœ¼ë¡œ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤")
    
    internal_results = []
    external_results = []
    
    try:
        if strategy == "internal_only":
            internal_results = internal_search_tool.invoke({"query": query, "k": 5})
            
        elif strategy == "external_priority":
            with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
                external_future = executor.submit(external_search_tool.invoke, {"query": query, "k": 3})
                internal_future = executor.submit(internal_search_tool.invoke, {"query": query, "k": 2})
                
                external_results = external_future.result()
                internal_results = internal_future.result()
                
        elif strategy == "hybrid_balanced":
            with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
                internal_future = executor.submit(internal_search_tool.invoke, {"query": query, "k": 3})
                external_future = executor.submit(external_search_tool.invoke, {"query": query, "k": 2})
                
                internal_results = internal_future.result()
                external_results = external_future.result()
                
        else:  # hybrid_internal_priority
            with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
                internal_future = executor.submit(internal_search_tool.invoke, {"query": query, "k": 4})
                external_future = executor.submit(external_search_tool.invoke, {"query": query, "k": 1})
                
                internal_results = internal_future.result()
                external_results = external_future.result()
        
        print(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: ë‚´ë¶€ {len(internal_results)}ê°œ, ì™¸ë¶€ {len(external_results)}ê°œ")
        
        return {
            **state,
            "internal_results": internal_results,
            "external_results": external_results,
            "step_count": state.get("step_count", 0) + 1
        }
        
    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            **state,
            "final_answer": f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}",
            "step_count": state.get("step_count", 0) + 1
        }

def answer_node(state: AgentState) -> AgentState:
    """ë‹µë³€ ìƒì„± ë…¸ë“œ"""
    query = state.get("query", "")
    internal_results = state.get("internal_results", [])
    external_results = state.get("external_results", [])
    strategy = state.get("search_strategy", "")
    
    print("ğŸ¤– ë‹µë³€ ë…¸ë“œ: ìµœì¢… ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤...")
    
    # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    context_parts = []
    
    # ë‚´ë¶€ ê²°ê³¼ ì²˜ë¦¬
    for i, doc in enumerate(internal_results, 1):
        speaker_name = doc.get('speaker_name', 'ë°œì–¸ì ë¯¸ìƒ')
        position = doc.get('position', '')
        speaker_info = f"{speaker_name} {position}" if position else speaker_name
        date_info = search_agents._safe_date_format(doc.get('minutes_date'))
        
        context_part = f"""
{i}ë²ˆì§¸ êµ­íšŒ íšŒì˜ë¡ ì •ë³´:
ë°œì–¸ì: {speaker_info}
íšŒì˜ì¼: {date_info}
ë‚´ìš©: {doc.get('content', '')}
"""
        context_parts.append(context_part)
    
    # ì™¸ë¶€ ê²°ê³¼ ì²˜ë¦¬
    for i, doc in enumerate(external_results, len(internal_results) + 1):
        title = doc.get('title', 'ì œëª© ì—†ìŒ')
        source_name = doc.get('source_name', 'ì›¹ ê²€ìƒ‰')
        
        context_part = f"""
{i}ë²ˆì§¸ ì›¹ ì •ë³´ ({source_name}):
ì œëª©: {title}
ë‚´ìš©: {doc.get('content', '')}
"""
        context_parts.append(context_part)
    
    context = "\n".join(context_parts)
    
    # ë‹µë³€ ìƒì„±
    system_prompt = """
ë‹¹ì‹ ì€ ì‹œê°ì¥ì• ì¸ì„ ìœ„í•œ ì •ë³´ ì „ë¬¸ í•´ì„¤ê°€ì…ë‹ˆë‹¤.
ìŒì„±ìœ¼ë¡œ ë“¤ì—ˆì„ ë•Œ ì´í•´í•˜ê¸° ì‰½ê³  ìì—°ìŠ¤ëŸ¬ìš´ ë‹µë³€ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.

ë‹µë³€ ì‘ì„± ì›ì¹™:
1. ìŒì„±ìœ¼ë¡œ ë“£ê¸° ì‰¬ìš´ ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ êµ¬ì¡° ì‚¬ìš©
2. ë³µì¡í•œ í•œìì–´ë‚˜ ì „ë¬¸ìš©ì–´ëŠ” ì‰¬ìš´ ë§ë¡œ í’€ì–´ì„œ ì„¤ëª…
3. êµ­íšŒ ì •ë³´ì™€ ì¼ë°˜ ì •ë³´ë¥¼ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ ì„¤ëª…
4. ìš”ì•½ê³¼ í•µì‹¬ ë‚´ìš©ì„ ë¨¼ì € ì œì‹œí•˜ê³  ìƒì„¸ ë‚´ìš© ì„¤ëª…
5. ë“£ëŠ” ì‚¬ëŒì´ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ë…¼ë¦¬ì  ìˆœì„œë¡œ êµ¬ì„±

ìŒì„± ì¹œí™”ì  í‘œí˜„ ì˜ˆì‹œ:
- "ì €ì¶œìƒ ë¬¸ì œ" â†’ "ì•„ì´ê°€ ì ê²Œ íƒœì–´ë‚˜ëŠ” ë¬¸ì œ"
- "êµ­ì •ê°ì‚¬" â†’ "êµ­íšŒì—ì„œ ì •ë¶€ ì¼ì„ ì ê²€í•˜ëŠ” í™œë™"
- "ì˜ˆì‚°ì•ˆ" â†’ "ë‚˜ë¼ì—ì„œ ì“¸ ëˆì„ ì •í•˜ëŠ” ê³„íš"
- "ë°œì˜ì•ˆ" â†’ "êµ­íšŒì˜ì›ì´ ìƒˆë¡œ ë§Œë“¤ìê³  ì œì•ˆí•œ ë²•ì•ˆ"
"""
    
    user_prompt = f"""
ì§ˆë¬¸: {query}

ì°¸ê³  ì •ë³´:
{context}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‹œê°ì¥ì• ì¸ì´ ìŒì„±ìœ¼ë¡œ ë“¤ì—ˆì„ ë•Œ ì´í•´í•˜ê¸° ì‰½ë„ë¡ ë‹µë³€í•´ì£¼ì„¸ìš”.

ë‹µë³€ êµ¬ì¡°:
1. í•µì‹¬ ìš”ì•½ (í•œ ë¬¸ì¥ìœ¼ë¡œ)
2. êµ­íšŒì—ì„œ ë…¼ì˜ëœ ë‚´ìš© (ìˆëŠ” ê²½ìš°)
3. ìµœì‹  ì¼ë°˜ ì •ë³´ (ìˆëŠ” ê²½ìš°)
4. ì¢…í•© ì •ë¦¬

ê° ë¶€ë¶„ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ì—¬ í¸ì•ˆí•˜ê²Œ ë“¤ì„ ìˆ˜ ìˆë„ë¡ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
    
    try:
        response = search_agents.openai_client.chat.completions.create(
            model=search_agents.chat_model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.3,
            max_tokens=2000
        )
        
        final_answer = response.choices[0].message.content
        
        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        start_time = state.get("processing_info", {}).get("start_time", time.time())
        processing_time = time.time() - start_time
        
        print(f"âœ¨ ë‹µë³€ ìƒì„± ì™„ë£Œ (ì²˜ë¦¬ ì‹œê°„: {processing_time:.1f}ì´ˆ)")
        
        return {
            **state,
            "final_answer": final_answer,
            "processing_info": {
                **state.get("processing_info", {}),
                "end_time": time.time(),
                "total_time": processing_time
            },
            "step_count": state.get("step_count", 0) + 1
        }
        
    except Exception as e:
        error_message = f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
        print(f"âŒ ë‹µë³€ ë…¸ë“œ: {error_message}")
        
        return {
            **state,
            "final_answer": error_message,
            "step_count": state.get("step_count", 0) + 1
        }

# ë¼ìš°íŒ… í•¨ìˆ˜ - ë¬´í•œ ë£¨í”„ ë°©ì§€
def route_after_entry(state: AgentState) -> Literal["strategy_node", "__end__"]:
    """ì§„ì…ì  ì´í›„ ë¼ìš°íŒ…"""
    query = state.get("query", "")
    step_count = state.get("step_count", 0)
    
    # ë‹¨ê³„ ìˆ˜ ì œí•œìœ¼ë¡œ ë¬´í•œ ë£¨í”„ ë°©ì§€
    if step_count > 10:
        print("âš ï¸ ìµœëŒ€ ë‹¨ê³„ ìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
        return "__end__"
    
    if query and query.strip():
        return "strategy_node"
    else:
        return "__end__"

def route_after_strategy(state: AgentState) -> Literal["search_node", "__end__"]:
    """ì „ëµ ê²°ì • ì´í›„ ë¼ìš°íŒ…"""
    strategy = state.get("search_strategy", "")
    step_count = state.get("step_count", 0)
    
    if step_count > 10:
        print("âš ï¸ ìµœëŒ€ ë‹¨ê³„ ìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
        return "__end__"
    
    if strategy:
        return "search_node"
    else:
        return "__end__"

def route_after_search(state: AgentState) -> Literal["answer_node", "__end__"]:
    """ê²€ìƒ‰ ì´í›„ ë¼ìš°íŒ…"""
    internal_results = state.get("internal_results", [])
    external_results = state.get("external_results", [])
    step_count = state.get("step_count", 0)
    
    if step_count > 10:
        print("âš ï¸ ìµœëŒ€ ë‹¨ê³„ ìˆ˜ì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤.")
        return "__end__"
    
    if internal_results or external_results:
        return "answer_node"
    else:
        return "__end__"

# ê·¸ë˜í”„ ë¹Œë” í•¨ìˆ˜
def create_agent_graph() -> StateGraph:
    """LangGraph ì—ì´ì „íŠ¸ ê·¸ë˜í”„ ìƒì„±"""
    
    # ê·¸ë˜í”„ ë¹Œë” ìƒì„±
    builder = StateGraph(AgentState)
    
    # ë…¸ë“œ ì¶”ê°€
    builder.add_node("entry_node", entry_node)
    builder.add_node("strategy_node", strategy_node)
    builder.add_node("search_node", search_node)
    builder.add_node("answer_node", answer_node)
    
    # ì‹œì‘ì  ì„¤ì •
    builder.add_edge(START, "entry_node")
    
    # ì¡°ê±´ë¶€ ì—£ì§€ ì¶”ê°€ (ë¬´í•œ ë£¨í”„ ë°©ì§€)
    builder.add_conditional_edges(
        "entry_node",
        route_after_entry,
        {
            "strategy_node": "strategy_node",
            "__end__": END
        }
    )
    
    builder.add_conditional_edges(
        "strategy_node",
        route_after_strategy,
        {
            "search_node": "search_node",
            "__end__": END
        }
    )
    
    builder.add_conditional_edges(
        "search_node",
        route_after_search,
        {
            "answer_node": "answer_node",
            "__end__": END
        }
    )
    
    # ë‹µë³€ ë…¸ë“œì—ì„œ ì¢…ë£Œ
    builder.add_edge("answer_node", END)
    
    return builder
